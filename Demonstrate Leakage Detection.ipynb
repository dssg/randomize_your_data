{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose: Demonstrate how leakage can be detected using a data randomization process.  \n",
    "Process: Create fake data using bernoulli GLM data-generating process (DGP). Intentionally leak information and then show that this code helps detect the leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from sklearn import metrics \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(filepath, index_col = None):\n",
    "    '''\n",
    "    Randomize column values of a file. Each column is randomized independently.\n",
    "    \n",
    "    Inputs:\n",
    "        filepath (str): path to file to randomize; may be of type csv or txt\n",
    "        index_col (str): optional name of column to use as index; will not be randomized\n",
    "    \n",
    "    Outputs:\n",
    "        df (dataframe): dataframe representation of randomized data\n",
    "        Output file will be generated, named as original file name + \"_randomized\"\n",
    "    '''\n",
    "    \n",
    "    # Treat csv and txt differently\n",
    "    filename, file_extension = os.path.splitext(filepath)\n",
    "    if file_extension == '.csv':\n",
    "        sep = \",\"\n",
    "    elif file_extension == '.txt':\n",
    "        sep = \"\\t\"\n",
    "        \n",
    "    # Randomize each column\n",
    "    df = pd.read_csv(filepath, sep = sep, index_col = index_col) \n",
    "    cols = df.columns\n",
    "    for col in cols:\n",
    "        print('... Randomizing column ' + col)\n",
    "        df[col] = np.random.permutation(df[col])\n",
    "        \n",
    "    # Print to new csv or txt\n",
    "    new_file = filename + '_randomized' + file_extension\n",
    "    df.to_csv(new_file)   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(period, n_rows, m_columns, threshold, betas, intercept):\n",
    "    '''\n",
    "    Generate fake data for a classification task, based on data generating process where:\n",
    "    - Features are drawn iid from standard normal distribution\n",
    "    - Regression equation: y = intercept + beta_1 * x1 + .. + beta_m * xm + error\n",
    "    - Error is drawn from standard normal distribution\n",
    "    - Outcome is 1 if p value from logistic function exceeds threshold, 0 otherwise\n",
    "    \n",
    "    Inputs:\n",
    "        period (int): time period\n",
    "        n_rows (int): number of observations to generate\n",
    "        m_columns (int): number of features to generate\n",
    "        betas (list): list of numerical values to use as coefficients; length must equal m_columns, \n",
    "            i.e. don't include intercept\n",
    "        intercept (int): constant number to use as intercept of regression equation\n",
    "        \n",
    "    Outputs:\n",
    "        X (dataframe): matrix of feature variables\n",
    "        y (series): outcome variable\n",
    "    '''\n",
    "    print(\"Generating {} observations...\".format(n_rows))\n",
    "    \n",
    "    # generate column names\n",
    "    colnames = []\n",
    "    for i in range(m_columns):\n",
    "        colnames.append('x' + str(i + 1))\n",
    "    \n",
    "    # generate fake data\n",
    "    df = pd.DataFrame(np.random.normal(size=(n_rows, m_columns)), columns = colnames)\n",
    "    df.insert(loc = 0, column = 'intercept', value = intercept)\n",
    "    betas = [1] + betas\n",
    "    df['z'] = np.multiply(np.array(betas), df).sum(axis=1) + np.random.normal()\n",
    "    df['pr'] = df['z'].apply(lambda x: 1/(1 + math.exp(x)))\n",
    "    df['outcome'] = np.where(df['pr'] > threshold, 1, 0)\n",
    "    df.index.name = 'idx'\n",
    "    df['period'] = period\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logreg(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    print(\"Baseline accuracy: \" + str(round(1 - np.mean(y_train), 2)))\n",
    "    \n",
    "    # Create a logistic regression object\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "\n",
    "    # Train model with training set\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions with test set\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Save probabilities\n",
    "    probs = logreg.predict_proba(X_test)\n",
    "\n",
    "    # Print accuracy and AUC\n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print(\"AUC Score: \" + str(metrics.roc_auc_score(y_test, probs[:, 1])))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logreg_pipeline(df):\n",
    "    '''\n",
    "    Put raw inputs through basic machine learning pipeline.\n",
    "    \n",
    "    Inputs:\n",
    "        dataframe: Pandas dataframe representing raw input file\n",
    "    \n",
    "    OUtputs:\n",
    "        logistic regression model object\n",
    "    '''\n",
    "    # Extract features and outcome from dataframe\n",
    "    X = df.drop(['z', 'pr', 'outcome'], axis = 1)\n",
    "    y = df['outcome']\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "   \n",
    "    return run_logreg(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Stable DGP (same parameters and threshold over time)\n",
    "### Non-temporal example with stable DGP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for 5 periods with constant DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(5):\n",
    "    period_df = generate_data(period = i, n_rows = 200, m_columns = 5, threshold = 0.8, betas = [1,2,3,4,5], intercept = 1)\n",
    "    frames.append(period_df)\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run original input file through pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6\n",
      "Accuracy: 0.951515151515\n",
      "AUC Score: 0.993717636308\n",
      "[[186  10]\n",
      " [  6 128]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the input file through randomization process, then run it through the pipeline. Model performs no better than random, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Randomizing column intercept\n",
      "... Randomizing column x1\n",
      "... Randomizing column x2\n",
      "... Randomizing column x3\n",
      "... Randomizing column x4\n",
      "... Randomizing column x5\n",
      "... Randomizing column z\n",
      "... Randomizing column pr\n",
      "... Randomizing column outcome\n",
      "... Randomizing column period\n",
      "Baseline accuracy: 0.61\n",
      "Accuracy: 0.584848484848\n",
      "AUC Score: 0.475776256571\n",
      "[[193   0]\n",
      " [137   0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx') # creates csv named fake_data.csv\n",
    "logreg_pipeline(df_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try introducing an obvious case of data leakage by using the probability column as a feature. Run this through the pipeline. Model performs well, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy: 0.6\n",
      "Accuracy: 0.978787878788\n",
      "AUC Score: 0.998730769231\n",
      "[[194   6]\n",
      " [  1 129]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['leaky_col'] = df['pr']\n",
    "logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the input file through randomization process. Again, introduce data leakage into the pipeline. Model performs better than random, thus suggesting the existence of data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Randomizing column intercept\n",
      "... Randomizing column x1\n",
      "... Randomizing column x2\n",
      "... Randomizing column x3\n",
      "... Randomizing column x4\n",
      "... Randomizing column x5\n",
      "... Randomizing column z\n",
      "... Randomizing column pr\n",
      "... Randomizing column outcome\n",
      "... Randomizing column period\n",
      "Baseline accuracy: 0.6\n",
      "Accuracy: 0.966666666667\n",
      "AUC Score: 0.997206917661\n",
      "[[190   8]\n",
      " [  3 129]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx') # generates csv named \"fake_data_randomized.csv\"\n",
    "df['leaky_col'] = df['pr']\n",
    "logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Regime change - intercept\n",
    "### The DGP is stable over time, then the intercept suddenly changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for 5 periods with intercept change in period 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n",
      "Generating 200 observations...\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for i in [0,1]:\n",
    "    period_df = generate_data(period = i, n_rows = 200, m_columns = 5, threshold = 0.8, betas = [1,2,3,4,5], intercept = 1)\n",
    "    frames.append(period_df)\n",
    "for i in [2,3,4]:\n",
    "    period_df = generate_data(period = i, n_rows = 200, m_columns = 5, threshold = 0.8, betas = [1,2,3,4,5], intercept = 10) \n",
    "    frames.append(period_df)\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('fake_data.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
