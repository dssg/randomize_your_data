{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose  \n",
    "Demonstrate how leakage can be detected using a data randomization process.  \n",
    "## Process\n",
    "Create fake data using linear data-generating process (DGP). Intentionally leak information and then show that this code helps detect the leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import TimeSeriesSplit, train_test_split\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "warnings.filterwarnings(action='once')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randomize(filepath, index_col = None, do_not_randomize = None):\n",
    "    \"\"\"\n",
    "    Randomize column values of a file. Each column is randomized independently.\n",
    "    \n",
    "    Inputs:\n",
    "        filepath (str): path to file to randomize; may be of type csv or txt\n",
    "        index_col (str): optional name of column to use as index; will not \n",
    "            be randomized\n",
    "        do_not_randomize (list): optional list of strings indicating names of \n",
    "            columns that should not be randomized\n",
    "    Outputs:\n",
    "        df (dataframe): dataframe representation of randomized data\n",
    "        Output file will be generated, named as original file name + \"_randomized\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Treat csv and txt differently\n",
    "    filename, file_extension = os.path.splitext(filepath)\n",
    "    if file_extension == '.csv':\n",
    "        sep = \",\"\n",
    "    elif file_extension == '.txt':\n",
    "        sep = \"\\t\"\n",
    "        \n",
    "    # Randomize column by column\n",
    "    df = pd.read_csv(filepath, sep = sep, index_col = index_col) \n",
    "    \n",
    "    if do_not_randomize:\n",
    "        cols = [c for c in df.columns if c not in do_not_randomize]\n",
    "    else:\n",
    "        cols = df.columns\n",
    "        \n",
    "    for col in cols:\n",
    "        print('... Randomizing column ' + col)\n",
    "        df[col] = np.random.permutation(df[col])\n",
    "        \n",
    "    # Print to new csv or txt\n",
    "    new_file = filename + '_randomized' + file_extension\n",
    "    df.to_csv(new_file)   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(period, n_rows, m_columns, threshold, betas, intercept):\n",
    "    \n",
    "    \"\"\" \n",
    "    Generate fake data for a classification task, based on data generating process where:\n",
    "    - Features are drawn iid from standard logistic distribution (location = 0, scale = 1)\n",
    "    - Regression equation: y = intercept + beta_1 * x1 + .. + beta_m * xm + error\n",
    "    - Error is drawn from standard normal distribution\n",
    "    - Outcome is 1 if p value from logistic function exceeds threshold, 0 otherwise\n",
    "\n",
    "    Inputs:\n",
    "        period (int): time period\n",
    "        n_rows (int): number of observations to generate\n",
    "        m_columns (int): number of features to generate\n",
    "        betas (list): list of numerical values to use as coefficients; length must equal m_columns, \n",
    "            i.e. don't include intercept\n",
    "        intercept (int): constant number to use as intercept of regression equation\n",
    "\n",
    "    Outputs:\n",
    "        X (dataframe): matrix of feature variables\n",
    "        y (series): outcome variable\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Generating {} observations...\".format(n_rows))\n",
    "\n",
    "    # generate column names\n",
    "    colnames = []\n",
    "    for i in range(m_columns):\n",
    "        colnames.append('x' + str(i + 1))\n",
    "\n",
    "    # generate fake data\n",
    "    df = pd.DataFrame(np.random.logistic(size=(n_rows, m_columns)), columns = colnames)\n",
    "    df.insert(loc = 0, column = 'intercept', value = 1)\n",
    "    betas = [intercept] + betas\n",
    "    df['z'] = np.multiply(np.array(betas), df).sum(axis=1) + np.random.normal()\n",
    "    df['pr'] = df['z'].apply(lambda x: 1/(1 + math.exp(x)))\n",
    "    df['outcome'] = np.where(df['pr'] > threshold, 1, 0)\n",
    "    df.index.name = 'idx'\n",
    "    df['period'] = period\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_logreg(X_train, y_train, X_test, y_test, plot = True, k=100):\n",
    "    \"\"\"\n",
    "    Run logistic regression on given test and training sets   \n",
    "    \n",
    "    Inputs\n",
    "        training and test sets\n",
    "        k (int): k value for which to obtain precision at k\n",
    "    \n",
    "    Output\n",
    "        dictionary containing logistic regresison model, test set, and evaluation metrics\n",
    "    \"\"\"\n",
    "    # Record baseline accuracy, i.e. percentage of positives in training set\n",
    "    baseline = np.mean(y_train)\n",
    "    print(\"Baseline accuracy (% positives in data): \" + str(round(baseline, 3)))\n",
    "    \n",
    "    # Create a logistic regression object\n",
    "    logreg = linear_model.LogisticRegression()\n",
    "\n",
    "    # Train model with training set\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions with test set\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Save probabilities\n",
    "    probs = logreg.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate accuracy, AUC, and precision at k\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_test, probs[:, 1])\n",
    "    \n",
    "    # Print accuracy and AUC\n",
    "    print(\"Accuracy: \" + str(round(accuracy, 3)))\n",
    "    print(\"AUC Score: \" + str(round(auc, 3)))\n",
    "    print(\"Precision at top {}: {}\".format(k, get_precision_at_k(y_test, y_pred, probs[:,1], k)))\n",
    "\n",
    "    # Print confusion matrix\n",
    "    print(metrics.confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    if plot:\n",
    "        # Plot AUC curve (source: https://datamize.wordpress.com/2015/01/24/how-to-plot-a-roc-curve-in-scikit-learn/)\n",
    "        false_positive_rate, true_positive_rate, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        print(\"FP rate: \", false_positive_rate, \"TP rate: \", true_positive_rate)\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.plot(false_positive_rate, true_positive_rate, 'b', label='AUC = %0.2f'% auc)\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.plot([0,1],[0,1],'r--')\n",
    "        plt.xlim([-0.1,1.2])\n",
    "        plt.ylim([-0.1,1.2])\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.show()\n",
    "\n",
    "    # Create output dictionary\n",
    "    output = {'model': logreg, 'baseline': baseline, 'X_test': X_test, 'y_test': y_test, 'y_pred': y_pred, 'probs': probs, 'accuracy': accuracy, 'auc': auc}\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(df):\n",
    "    \"\"\"\n",
    "    Split data frame into X and y objects \n",
    "    \"\"\"\n",
    "    X = df.drop(['z', 'pr', 'outcome'], axis = 1)\n",
    "    y = df['outcome']\n",
    "    return X, y\n",
    "\n",
    "def logreg_pipeline(df, temporal = False, plot = True):\n",
    "    \"\"\"\n",
    "    Put raw inputs through basic machine learning pipeline.\n",
    "    \n",
    "    Inputs:\n",
    "        df (dataframe): Pandas dataframe representing raw input file\n",
    "        temporal (bool): Indicator for whether a temporal TimeSeriesSplit\n",
    "            should be use instead of non-temporal train_test_split\n",
    "        plot (bool): Indicator for whether to plot the auc curve\n",
    "    Outputs:\n",
    "        list of logistic regression model dictionaries; length = 1 when temporal == False\n",
    "    \"\"\"\n",
    "    # Save results of run_logreg\n",
    "    models = []\n",
    "    \n",
    "    # Split into train and test sets\n",
    "    if temporal: # do temporal train-test split\n",
    "        periods = np.sort(df.period.unique())\n",
    "        splits = TimeSeriesSplit(n_splits = max(periods))\n",
    "        print(\"\\nTime series split\")\n",
    "        for train_index, test_index in splits.split(periods):\n",
    "            df_train = df[df.period.isin(train_index)]\n",
    "            df_test = df[df.period.isin(test_index)]\n",
    "            print(\"df_test shape: \", df_test.shape)\n",
    "            X_train, y_train = get_X_y(df_train)\n",
    "            X_test, y_test = get_X_y(df_test)\n",
    "            models.append(run_logreg(X_train, y_train, X_test, y_test, plot, k=100))\n",
    "\n",
    "    else: # do random, non-temporal train-test split\n",
    "        print(\"\\nTrain test split -- test size = 0.33\")\n",
    "        X, y = get_X_y(df)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "        models.append(run_logreg(X_train, y_train, X_test, y_test, plot, k=100))\n",
    "    \n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_precision_at_k(y_test, y_pred, probs, k):\n",
    "    \"\"\"\n",
    "    Calculate precision at top k observations\n",
    "    \n",
    "    Inputs\n",
    "        y_test (series)\n",
    "        y_pred (array)\n",
    "        probs (array)\n",
    "        k (int)\n",
    "    Outputs\n",
    "        precision_at_k (float)\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.transpose([np.asarray(y_test), y_pred, probs]), columns = ['y_test', 'y_pred', 'probs'])\n",
    "    df_sorted = df.sort_values(by='probs', ascending = False)\n",
    "    df_topk = df_sorted.iloc[:k,:]\n",
    "    precision_at_k = metrics.precision_score(df_topk.y_test, df_topk.y_pred)\n",
    "\n",
    "    return precision_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bootstrap_metrics(df, bootstrap_n, k, temporal = False):\n",
    "    \"\"\"\n",
    "    Sample with replacement from original data frame a number of times. Run logistic regression pipeline on each sample\n",
    "    to obtain a distribution of AUC scores for significance testing.\n",
    "    \n",
    "    Inputs\n",
    "        df (dataframe): Pandas dataframe representing raw input file\n",
    "        bootstrap_n (int): number of bootstrap samples to run\n",
    "        k (int): k value for which to obtain precision at k\n",
    "        temporal (bool): Indicator for whether a temporal TimeSeriesSplit\n",
    "            should be use instead of non-temporal train_test_split\n",
    "        \n",
    "    Outputs\n",
    "        auc_array (array): array of auc scores of dimension bootstrap_n x num_temporal_tests\n",
    "        precision_k_array (array): array of precision at top k scores of dimension bootstrap_n x num_temporal_tests\n",
    "    \"\"\"\n",
    "    \n",
    "    all_iterations = []\n",
    "    for n in range(bootstrap_n):\n",
    "        sample = df.sample(df.shape[0], replace=True)\n",
    "        all_iterations.append(logreg_pipeline(sample, temporal, plot = False))\n",
    "    \n",
    "    if temporal: \n",
    "        auc_scores = [[d['auc'] for d in iteration] for iteration in all_iterations]\n",
    "        auc_array = np.array(auc_scores)\n",
    "        \n",
    "        precision_k_scores = [[get_precision_at_k(d['y_test'], d['y_pred'], d['probs'][:, 1], k) for d in iteration] for iteration in all_iterations]\n",
    "        precision_k_array = np.array(precision_k_scores)\n",
    "        \n",
    "    else: \n",
    "        auc_scores = [iteration[0]['auc'] for iteration in all_iterations]\n",
    "        auc_array = np.array(auc_scores)[:,np.newaxis]\n",
    "        \n",
    "        precision_k_scores = [get_precision_at_k(iteration[0]['y_test'], iteration[0]['y_pred'], iteration[0]['probs'][:, 1], k) for iteration in all_iterations]\n",
    "        precision_k_array = np.array(precision_k_scores)[:, np.newaxis]\n",
    "    \n",
    "    return auc_array, precision_k_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sig_test(scores_array, metric_name, baseline, m):\n",
    "    \"\"\"\n",
    "    Use traditional significance test to check for nonrandom effects\n",
    "    \n",
    "    Goal: argue for a statistically significant effect, i.e. scores are different from random\n",
    "    H0: avg score = baseline, i.e. random\n",
    "    H1: avg score != baseline, i.e. different from random\n",
    "    \n",
    "    We reject null at significance level of alpha = 0.05 \n",
    "    \n",
    "    Inputs\n",
    "        scores_array (array): array of scores from bootstrapped samples; scores can be auc, precision at k, etc\n",
    "        metric_name (str): \"auc\" or \"precision_at_k\"\n",
    "        baseline (float): expected score for a random classifier; ex: 0.5 for AUC, % positives for precision\n",
    "            \n",
    "    Outputs\n",
    "        p (float): p value\n",
    "    \"\"\"\n",
    "    print(\"Performing two-sided t-test for \", metric_name)\n",
    "    \n",
    "    sample_mean = np.mean(scores_array)\n",
    "    std_error = np.std(scores_array, ddof=1, dtype=np.float64) # unbiased estimator\n",
    "    print(\"Baseline {}: {}\".format(metric_name, round(baseline, 6)))\n",
    "    print(\"Sample mean {}: {}\".format(metric_name, round(sample_mean, 6)))\n",
    "    print(\"Standard error: \", round(std_error, 6))\n",
    "    \n",
    "    # zero standard error: no statistical doubt that sample mean is true mean\n",
    "    # rounding to 10 decimal points because of zero precision issues\n",
    "    if np.around(std_error, 10) == 0.0 : \n",
    "        print(\"Something's wrong: zero standard error!\")\n",
    "        if abs(sample_mean - baseline) < 0.00000000001:\n",
    "            print('Fail to reject null at significance level 0.0')\n",
    "            print('Avg {} is no different from random'.format(metric_name))\n",
    "        else:\n",
    "            print('Reject null at significance level 0.0')\n",
    "            print('Avg {} is different from random'.format(metric_name))\n",
    "        return 1.0\n",
    "    \n",
    "    deg = scores_array.size - 1\n",
    "    \n",
    "    # Compute p-val\n",
    "    t = (sample_mean - baseline) / std_error\n",
    "    p = 1 - stats.t.cdf(x = abs(t), df = deg)\n",
    "    print(\"t-score: \", t, \"p-val: \", p)\n",
    "    \n",
    "    # reject null if significance level of 0.05 or lower is achieved\n",
    "    if p <= 0.05:\n",
    "        print('Reject null at significance level ', round(p, 6))\n",
    "        print('Avg {} is different from random'.format(metric_name))\n",
    "    else:\n",
    "        print('Fail to reject null at significance level ', round(p, 6))\n",
    "        print('Avg {} is no different from random'.format(metric_name))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tost(scores_array, baseline, m):\n",
    "    \"\"\"\n",
    "    Use two one-sided significance test (TOST) to check for negligible effect, as described here: \n",
    "        http://www.carlislerainey.com/papers/nme.pdf\n",
    "    \n",
    "    Goal: argue for an empirically negligible effect, i.e. scores are no different from random\n",
    "    H0: avg score is in [0, baseline - m] U [baseline + m, 1], i.e. different from random\n",
    "    H1: avg score is in [baseline - m, baseline + m], i.e. same as random\n",
    "    \n",
    "    p-value of a TOST is the maximum of the p-values of each one-sided test\n",
    "    We reject null at significance level of alpha = 0.05 \n",
    "    \n",
    "    Inputs\n",
    "        scores_array (array): array of scores from bootstrapped samples; scores can be auc, precision at k, etc\n",
    "        baseline (float): expected score for a random classifier; ex: 0.5 for AUC, % positives for precision\n",
    "        m (float):  We assume that the smallest substantially meaningful effect for results to be different from random\n",
    "            is when score is m different from baseline (random).\n",
    "            \n",
    "    Outputs\n",
    "        p (float): p value\n",
    "    \"\"\" \n",
    "    print(\"Performing two one-sided t-tests (TOST) for \", metric_name)\n",
    "\n",
    "    sample_mean = np.mean(scores_array)\n",
    "    std_error = np.std(scores_array, ddof=1, dtype=np.float64) # unbiased estimator\n",
    "    print(\"Baseline {}: {}\".format(metric_name, round(baseline, 6)))\n",
    "    print(\"Sample mean {}: {}\".format(metric_name, round(sample_mean, 6)))\n",
    "    print(\"Standard error: \", round(std_error, 6))\n",
    "    \n",
    "    # zero standard error: no statistical doubt that sample mean is true mean\n",
    "    # rounding to 10 decimal points because of zero precision issues\n",
    "    if np.around(std_error, 10) == 0.0 : \n",
    "        print(\"Something's wrong: zero standard error!\")\n",
    "        if sample_mean > baseline - m and sample_mean < baseline + m:\n",
    "            print('Reject null at significance level 0.0')\n",
    "            print('Avg {} is no different from random'.format(metric_name))\n",
    "        else:\n",
    "            print('Fail to reject null at significance level 0.0')\n",
    "            print('Avg {} is different from random'.format(metric_name))\n",
    "        return 1.0\n",
    "    \n",
    "    deg = scores_array.size - 1\n",
    "    \n",
    "    # Compute p-val for side 1: score is in [0, baseline - m]\n",
    "    t1 = (sample_mean - (baseline - m)) / std_error\n",
    "    p1 = 1 - stats.t.cdf(x = abs(t1), df = deg)\n",
    "    print(\"t1: \", t1, \"p1: \", p1)\n",
    "    \n",
    "    # Compute p-val for side 2: score is in [baseline + m, 1]\n",
    "    t2 = (sample_mean - (baseline + m)) / std_error\n",
    "    p2 = 1 - stats.t.cdf(x = abs(t2), df = deg)\n",
    "    print(\"t2: \", t2, \"p2: \", p2)\n",
    "    \n",
    "    # p-val is max of the two one-sided tests\n",
    "    p = max(p1, p2)\n",
    "    \n",
    "    # reject null if significance level of 0.05 or lower is achieved\n",
    "    if p <= 0.05:\n",
    "        print('Reject null at significance level ', round(p, 6))\n",
    "        print('Avg {} is no different from random'.format(metric_name))\n",
    "    else:\n",
    "        print('Fail to reject null at significance level ', round(p, 6))\n",
    "        print('Avg {} is different from random'.format(metric_name))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1: Stable DGP \n",
    "### Non-temporal example with stable DGP; data leakage through outcome variable as a feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for 5 periods with constant DGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 2000 observations...\n",
      "Generating 2000 observations...\n",
      "Generating 2000 observations...\n",
      "Generating 2000 observations...\n",
      "Generating 2000 observations...\n"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(5):\n",
    "    period_df = generate_data(period = i, n_rows = 2000, m_columns = 5, threshold = 0.5, betas = [1,2,3,4,5], intercept = 1)\n",
    "    frames.append(period_df)\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run original input file through pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train test split -- test size = 0.33\n",
      "Baseline accuracy (% positives in data): 0.487\n",
      "Accuracy: 0.988\n",
      "AUC Score: 0.999\n",
      "Precision at top 100: 1.0\n",
      "[[1725   22]\n",
      " [  17 1536]]\n",
      "FP rate:  [ 0.          0.01259302  1.        ] TP rate:  [ 0.          0.98905344  1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRCQjBYWIiGSkoBARkYwUFCIiktH/A2qlUi+px9aQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f762413128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the input file through randomization process, then run it through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Randomizing column intercept\n",
      "... Randomizing column x1\n",
      "... Randomizing column x2\n",
      "... Randomizing column x3\n",
      "... Randomizing column x4\n",
      "... Randomizing column x5\n",
      "... Randomizing column z\n",
      "... Randomizing column pr\n",
      "\n",
      "Train test split -- test size = 0.33\n",
      "Baseline accuracy (% positives in data): 0.484\n",
      "Accuracy: 0.504\n",
      "AUC Score: 0.492\n",
      "Precision at top 100: 0.48\n",
      "[[1329  396]\n",
      " [1241  334]]\n",
      "FP rate:  [ 0.          0.22956522  1.        ] TP rate:  [ 0.          0.21206349  1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnqGyo40K+AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f766a65668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx', ['period', 'outcome']) # creates csv named fake_data_randomized.csv\n",
    "models = logreg_pipeline(df_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform statistical test on bootstrapped samples. Expect to see that model performs no better than random because data has been randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "auc_array, precision_k_array = bootstrap_metrics(df_random, 1000, k=100, temporal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC and precision at k scores are what we'd expect; they are no different from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing two-sided t-test for  auc\n",
      "Baseline auc: 0.5\n",
      "Sample mean auc: 0.508027\n",
      "Standard error:  0.011054\n",
      "t-score:  0.726149357656 p-val:  0.233958651674\n",
      "Fail to reject null at significance level  0.233959\n",
      "Avg auc is no different from random\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.23395865167438634"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_test(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing two-sided t-test for  precision_at_k\n",
      "Baseline precision_at_k: 0.4819\n",
      "Sample mean precision_at_k: 0.501695\n",
      "Standard error:  0.072558\n",
      "t-score:  0.272815148319 p-val:  0.392525848262\n",
      "Fail to reject null at significance level  0.392526\n",
      "Avg precision_at_k is no different from random\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.39252584826184378"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_test(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tost() got an unexpected keyword argument 'metric_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-583f99b60b12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbaseline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: tost() got an unexpected keyword argument 'metric_name'"
     ]
    }
   ],
   "source": [
    "tost(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at top 100 scores are NOT what we'd expect; they are statistically different from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tost(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try introducing an obvious case of data leakage by using the outcome column as a feature. Run this through the pipeline. Model performs well, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['leaky_col'] = df['outcome']\n",
    "models = logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the input file through randomization process. Again, introduce data leakage into the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx', ['period', 'outcome']) # generates csv named \"fake_data_randomized.csv\"\n",
    "df_random['leaky_col'] = df_random['outcome']\n",
    "models = logreg_pipeline(df_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Perform statistical test on bootstrapped samples. Expect to see that model performs  better than random, thus suggesting the existence of data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "auc_array, precision_k_array = bootstrap_metrics(df_random, 1000, k=100, temporal=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC scores are what we'd expect; they are different from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tost(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision at top 100 scores are what we'd expect; they are different from random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tost(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2: Stable DGP\n",
    "### Non-temporal example with stable DGP; data leakage through selection of variables that are highly correlated with outcome (i.e. proxy variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data with 1000 variables for 5 periods with constant DGP. Betas are random integers between 0 and 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in range(5):\n",
    "    period_df = generate_data(period = i, n_rows = 2000, m_columns = 1000, threshold = 0.5, betas = list(np.random.randint(0, 5, size=1000)), intercept = 1)\n",
    "    frames.append(period_df)\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run original input file through pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute correlation of each variable with outcome variable. Select top 100 highest positively-correlated variables to use as features.\n",
    "\n",
    "Model performs worse now than when all variables are used as features. This is expected because outcome is a function of all 1000 variables in true relationship, so predictive power of 100 variables is not as high as 1000 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correlations = []\n",
    "for i in range(1000):\n",
    "    corr_coeff = df['x'+str(i + 1)].corr(df.outcome)\n",
    "    correlations.append((i+1, corr_coeff))\n",
    "top_100 = sorted(correlations, key=lambda x: x[1])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices = [\"x\"+str(x[0]) for x in top_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df[['intercept'] + indices + ['z', 'pr', 'outcome']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3: Regime change - intercept \n",
    "### DGP is stable over time, then the intercept suddenly changes; data leakage through non-temporal train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data for 5 periods with intercept change in period 2  \n",
    "Dataset is in temporal order by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = []\n",
    "for i in [0,1]:\n",
    "    period_df = generate_data(period = i, n_rows = 2000, m_columns = 5, threshold = 0.5, betas = [1,2,3,4,5], intercept = 1)\n",
    "    frames.append(period_df)\n",
    "for i in [2,3,4]:\n",
    "    period_df = generate_data(period = i, n_rows = 2000, m_columns = 5, threshold = 0.5, betas = [1,2,3,4,5], intercept = 3) \n",
    "    frames.append(period_df)\n",
    "df = pd.concat(frames)\n",
    "df.to_csv('fake_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run pipeline using appropriate temporal train-test split. Model does well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = logreg_pipeline(df, temporal=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put input file through randomization process, then run it through the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx', ['period', 'outcome']) # creates csv named fake_data_randomized.csv\n",
    "models = logreg_pipeline(df_random, temporal = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform statistical test to confirm that model performs no better than random  \n",
    "QUESTION: How to interpret the conflicting results for precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "auc_array, precision_k_array = bootstrap_metrics(df_random, 1000, k=100, temporal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tost(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tost(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, introduce data leakage by using non-temporal train-test split. Run this through the pipeline. Model performs well, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = logreg_pipeline(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe model performance in each period of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0] # list only contains one dictionary because we ran a non-temporal pipeline\n",
    "\n",
    "periods = np.sort(df.period.unique())\n",
    "\n",
    "test_df = model['X_test']\n",
    "test_df['y_test'] = model['y_test']\n",
    "test_df['y_pred'] = model['y_pred']\n",
    "test_df['probs'] = model['probs'][:, 1]\n",
    "\n",
    "for i in periods:\n",
    "    print(\"\\nWhen test period is {}...\".format(i))\n",
    "    df_i = test_df[test_df.period == i]\n",
    "    acc = metrics.accuracy_score(df_i.y_test, df_i.y_pred)\n",
    "    auc = metrics.roc_auc_score(df_i.y_test, df_i.probs)\n",
    "    prec = get_precision_at_k(df_i.y_test, df_i.y_pred, df_i.probs, 100)\n",
    "    print(\"Accuracy: {}\".format(round(acc,5)))\n",
    "    print(\"AUC: {}\".format(round(auc,5)))\n",
    "    print(\"Precision at top 100: {}\".format(round(prec, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the input file through randomization process, randomizing all columns except period and outcome. Again, introduce data leakage into the pipeline by using non-temporal train-test split. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_random = randomize('fake_data.csv', 'idx', ['period', 'outcome']) # generates csv named \"fake_data_randomized.csv\"\n",
    "models = logreg_pipeline(df_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe model performance in each period of the test data. We can see that this data leakage causes higher accuracy in the period when the data generating process changes, because information about the future has been leaked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = models[0] # list only contains one dictionary because we ran a non-temporal pipeline\n",
    "\n",
    "periods = np.sort(df.period.unique())\n",
    "\n",
    "test_df = model['X_test']\n",
    "test_df['y_test'] = model['y_test']\n",
    "test_df['y_pred'] = model['y_pred']\n",
    "test_df['probs'] = model['probs'][:, 1]\n",
    "\n",
    "for i in periods:\n",
    "    print(\"\\nWhen test period is {}....\".format(i))\n",
    "    df_i = test_df[test_df.period == i]\n",
    "    acc = metrics.accuracy_score(df_i.y_test, df_i.y_pred)\n",
    "    auc = metrics.roc_auc_score(df_i.y_test, df_i.probs)\n",
    "    prec = get_precision_at_k(df_i.y_test, df_i.y_pred, df_i.probs, 100)\n",
    "    print(\"Accuracy: {}\".format(round(acc, 5)))\n",
    "    print(\"AUC: {}\".format(round(auc,5)))\n",
    "    print(\"Precision at top 100: {}\".format(round(prec, 5)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform statistical test to confirm that model performs better than random, thus suggesting data leakage  \n",
    "QUESTION: We expected this model to do better, but test shows that auc and precision are no different from random; precision is actually worse. What's going on here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "auc_array, precision_k_array = bootstrap_metrics(df_random, 1000, k=100, temporal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(auc_array, metric_name = 'auc', baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_test(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tost(auc_array, metric_name = 'auc',baseline = 0.5, m = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tost(precision_k_array, metric_name = 'precision_at_k', baseline = np.mean(df_random.outcome), m = 0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
