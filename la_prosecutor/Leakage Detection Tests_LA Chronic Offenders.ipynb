{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leakage Detection Tests\n",
    "\n",
    "A series of tests for leakage, demonstrated on the [Los Angeles Chronic Offenders Leakage](https://github.com/dssg/la_prosecutor) project  \n",
    "Requires a credentials.py file defining the following variables: dbname, user, host, password, port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from credentials import dbname, user, host, password, port\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "warnings.filterwarnings(action='once')\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(statement, dbname, user, host, password, port, isolation = False, results = True):\n",
    "    \"\"\"\n",
    "    Use psycopg2 to execute PostgreSQL queries\n",
    "    \n",
    "    Input:\n",
    "        statement (str): SQL statement to run in database\n",
    "        dbname, user, host, password (str): database credentials\n",
    "        isolation (bool): indicator for whether to change isolation level to autocommit; True for queries that cannot be run \n",
    "            from within a transation (see https://wiki.postgresql.org/wiki/Psycopg2_Tutorial)\n",
    "        results (bool): indicator for whether the query is expected to output results;\n",
    "            for example, True for SELECT statements and False for CREATE TABLE statements\n",
    "    \n",
    "    Output:\n",
    "        relation (dataframe): query results or empty dataframe if results = False\n",
    "    \"\"\"\n",
    "    conn = psycopg2.connect(\"dbname={} user={} host={} password={}\".format(dbname, user, host, password))\n",
    "    cur = conn.cursor()\n",
    "    if isolation:\n",
    "        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "    cur.execute(statement)\n",
    "    relation = pd.DataFrame()\n",
    "    if results:\n",
    "        results = cur.fetchall()\n",
    "        colnames = [desc[0] for desc in cur.description]\n",
    "        relation = pd.DataFrame(results, columns=colnames)\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return relation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(df, do_not_randomize = None):\n",
    "    \"\"\"\n",
    "    Randomize column values of a file. Each column is randomized independently.\n",
    "    \n",
    "    Inputs:\n",
    "        df (dataframe): dataframe to randomize\n",
    "        do_not_randomize (list): optional list of strings indicating names of \n",
    "            columns that should not be randomized\n",
    "    Outputs:\n",
    "        df (dataframe): dataframe of randomized data\n",
    "    \"\"\"     \n",
    "    df_random = df.copy()\n",
    "    if do_not_randomize:\n",
    "        cols = [c for c in df.columns if c not in do_not_randomize]\n",
    "    else:\n",
    "        cols = df.columns\n",
    "        \n",
    "    for col in cols:\n",
    "        #print('\\t\\tRandomizing column ' + col)\n",
    "        df_random[col] = np.random.permutation(df_random[col])\n",
    "\n",
    "    return df_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://overlaid.net/2016/02/08/replace-words-in-files-or-strings-using-python/\n",
    "def do_replacement(base_text, word_map):\n",
    "    \"\"\"\n",
    "    Helper function for replace_words_in_file. Make replacements in base_text, as \n",
    "    indicated in  word_map.\n",
    "    \"\"\"\n",
    "    for key, val in word_map.items():\n",
    "        base_text = base_text.replace(key, val)\n",
    "    return base_text\n",
    "\n",
    "def replace_words_in_file(read_from, write_to, word_map):\n",
    "    \"\"\"\n",
    "    Create copy of a file with certain words replaced\n",
    "    \n",
    "    Inputs\n",
    "        read_from: name of file to read from\n",
    "        write_to: name of new file to be created\n",
    "        word_map: dictionary of mappings between words and their replacements\n",
    "            (e.g. {'old_word': 'new_word'})\n",
    "    Outputs\n",
    "        None. Will create a new file with the name given in write_to\n",
    "        \n",
    "    \"\"\"\n",
    "    print('Generating file ', write_to)\n",
    "    # Open your desired file as 't' and read the lines into string 'tempstr'\n",
    "    t = open(read_from, 'r')\n",
    "    tempstr = t.read()\n",
    "    t.close()\n",
    "\n",
    "    # Using the \"replace_words\" function, we'll pass in our tempstr to be used as the base, \n",
    "    # and our device_values to be used as replacement.  \n",
    "    output = do_replacement(tempstr, word_map)\n",
    "\n",
    "    # Write out the new config file\n",
    "    fout = open(write_to, 'w')\n",
    "    fout.write(output)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_filename(filename, suffix, replacement_map=None):\n",
    "    \"\"\"\n",
    "    Output a new filename (str) given a filename and suffix to append. Assumes file extension at the end is separated by a period.\n",
    "    \"\"\"\n",
    "    k = filename.rfind(\".\")\n",
    "    new_filename = filename[:k] + suffix + '.' + filename[k+1:]\n",
    "    if replacement_map:\n",
    "        new_filename = do_replacement(new_filename, replacement_map)\n",
    "    return new_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Randomize the input data\n",
    "\n",
    "A number of preprocessing steps were required for this project, because raw cases and bookings data did not come with unique identifiers for the individuals involved. As such, we cannot randomize the raw data because we would be unable to identify individuals in the results. Randomization must be done after entity linkage but before features are built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull the information schema from selected database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name of the database schema containing input data to be randomized\n",
    "INPUT_SCHEMA = 'staging' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM information_schema.tables;\"\n",
    "tables = execute_sql(statement, dbname, user, host, password, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the schema containing input datasets to be randomized. For this project, the schema is named staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tables = tables.table_name[tables.table_schema == INPUT_SCHEMA]\n",
    "input_tables = list(input_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First created the _randomized schema if it doesn't yet exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"CREATE SCHEMA IF NOT EXISTS {}_randomized;\".format(INPUT_SCHEMA)\n",
    "output = execute_sql(statement, dbname, user, host, password, port, isolation=True, results = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy over all the tables from original input schema, i.e. all tables in input_tables list.\n",
    "\n",
    "Randomize only a subset of these tables. Tables to be randomized are:    \n",
    "1) The set of tables from the staging schema that are referenced in the from\\_obj section of each of the yaml files in /config/features. These staging tables have been linked to entity identifiers and are the source data for feature generation.  \n",
    "2) The two tables from the staging schema that are referenced in the experiment config file, used for label generation and state management. IS THIS NECESSARY?\n",
    "\n",
    "Note that table names beginning with \"staging.entity_\" are not included in the list because they contain mappings between entity identifiers and other data. These relationships must be maintained so should not be randomized.\n",
    "\n",
    "Write output to _randomized schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addinfo',\n",
       " 'booking',\n",
       " 'booking_addl_info',\n",
       " 'branch_lkup',\n",
       " 'case_booking',\n",
       " 'case_dispo_lkup',\n",
       " 'case_flag_lkup',\n",
       " 'case_result_lkup',\n",
       " 'cases',\n",
       " 'casesaka',\n",
       " 'casescharge',\n",
       " 'casesflag',\n",
       " 'ccms_to_ucc',\n",
       " 'charge_categories',\n",
       " 'charge_lkup',\n",
       " 'citation',\n",
       " 'docass',\n",
       " 'entity_address',\n",
       " 'entity_aka',\n",
       " 'entity_all_events',\n",
       " 'entity_any_name',\n",
       " 'entity_best_demos',\n",
       " 'entity_booking',\n",
       " 'entity_case',\n",
       " 'entity_cii',\n",
       " 'entity_dmv',\n",
       " 'entity_dob',\n",
       " 'entity_gender',\n",
       " 'entity_main_number',\n",
       " 'entity_name',\n",
       " 'entity_race',\n",
       " 'feature_case_info',\n",
       " 'feature_case_results',\n",
       " 'feature_casesflag_info',\n",
       " 'feature_charge_info',\n",
       " 'firstname_gender',\n",
       " 'firstname_race',\n",
       " 'labels_1prior_win6mo_lab6mo',\n",
       " 'labels_casesonly_multiprior_win6mo_lab6mo',\n",
       " 'labels_multiprior_win6mo_lab6mo',\n",
       " 'lastname_race',\n",
       " 'orig_agency_lkup',\n",
       " 'prob',\n",
       " 'probcon',\n",
       " 'states_win6mo_lab6mo',\n",
       " 'status_h',\n",
       " 'turkey_list']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tables_to_randomize = [\n",
    "               'booking_addl_info', \n",
    "               'branch_lkup',\n",
    "               'case_booking',  \n",
    "               'case_dispo_lkup', \n",
    "               'case_flag_lkup',\n",
    "               'case_result_lkup',\n",
    "               'charge_lkup',\n",
    "               'feature_casesflag_info', \n",
    "               'feature_case_info', \n",
    "               'feature_case_results',\n",
    "               'feature_charge_info',\n",
    "               'labels_casesonly_multiprior_win6mo_lab6mo',\n",
    "               'orig_agency_lkup',\n",
    "               'labels_multiprior_win6mo_lab6mo'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on table addinfo\n",
      "\tUploading original version without randomizing\n",
      "Working on table booking\n",
      "\tUploading original version without randomizing\n",
      "Working on table booking_addl_info\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table branch_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table case_booking\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table case_dispo_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table case_flag_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table case_result_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table cases\n",
      "\tUploading original version without randomizing\n",
      "Working on table casesaka\n",
      "\tUploading original version without randomizing\n",
      "Working on table casescharge\n",
      "\tUploading original version without randomizing\n",
      "Working on table casesflag\n",
      "\tUploading original version without randomizing\n",
      "Working on table ccms_to_ucc\n",
      "\tUploading original version without randomizing\n",
      "Working on table charge_categories\n",
      "\tUploading original version without randomizing\n",
      "Working on table charge_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table citation\n",
      "\tUploading original version without randomizing\n",
      "Working on table docass\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_address\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_aka\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_all_events\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_any_name\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_best_demos\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_booking\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_case\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_cii\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_dmv\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_dob\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_gender\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_main_number\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_name\n",
      "\tUploading original version without randomizing\n",
      "Working on table entity_race\n",
      "\tUploading original version without randomizing\n",
      "Working on table feature_case_info\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table feature_case_results\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table feature_casesflag_info\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table feature_charge_info\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table firstname_gender\n",
      "\tUploading original version without randomizing\n",
      "Working on table firstname_race\n",
      "\tUploading original version without randomizing\n",
      "Working on table labels_1prior_win6mo_lab6mo\n",
      "\tUploading original version without randomizing\n",
      "Working on table labels_casesonly_multiprior_win6mo_lab6mo\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table labels_multiprior_win6mo_lab6mo\n",
      "\tUploading original version without randomizing\n",
      "\t*****SKIPPING TABLE labels_multiprior_win6mo_lab6mo -- it already has data\n",
      "Working on table lastname_race\n",
      "\tUploading original version without randomizing\n",
      "Working on table orig_agency_lkup\n",
      "\tPulling table\n",
      "\tRandomizing\n",
      "\tUploading randomized version\n",
      "Working on table prob\n",
      "\tUploading original version without randomizing\n",
      "Working on table probcon\n",
      "\tUploading original version without randomizing\n",
      "Working on table states_win6mo_lab6mo\n",
      "\tUploading original version without randomizing\n",
      "\t*****SKIPPING TABLE states_win6mo_lab6mo -- it already has data\n",
      "Working on table status_h\n",
      "\tUploading original version without randomizing\n",
      "Working on table turkey_list\n",
      "\tUploading original version without randomizing\n"
     ]
    }
   ],
   "source": [
    "for table_name in input_tables:\n",
    "    print(\"Working on table {}\".format(table_name))\n",
    "    \n",
    "    if table_name in input_tables_to_randomize: # randomize before adding to _randomized schema\n",
    "        # Pull the table from original schema\n",
    "        print(\"\\tPulling table\")\n",
    "        statement = \"SELECT * FROM {}.{};\".format(INPUT_SCHEMA, table_name)\n",
    "        table = execute_sql(statement, dbname, user, host, password, port)\n",
    "\n",
    "        # Randomize the table\n",
    "        print(\"\\tRandomizing\")\n",
    "        randomized_table = randomize(table)\n",
    "\n",
    "        # Make a new table in _randomized schema\n",
    "        print(\"\\tUploading randomized version\")\n",
    "        statement = \"CREATE TABLE IF NOT EXISTS {0}_randomized.{1}_randomized (LIKE {0}.{1} INCLUDING ALL);\".format(INPUT_SCHEMA, table_name)\n",
    "        output = execute_sql(statement, dbname, user, host, password, port, isolation = True, results = False)\n",
    "\n",
    "        # Write results into new table\n",
    "        statement = \"SELECT COUNT(*) FROM {}_randomized.{}_randomized;\".format(INPUT_SCHEMA, table_name)\n",
    "        output = execute_sql(statement, dbname, user, host, password, port)\n",
    "        if output.iloc[0,0]>0: # do nothing if new table already contains data\n",
    "            print(\"\\t*****SKIPPING TABLE {}_randomized -- it already has data\".format(table_name))\n",
    "        else:\n",
    "            engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(user, password, host, port, dbname))\n",
    "            randomized_table.to_sql(table_name+'_randomized', engine, schema = '{}_randomized'.format(INPUT_SCHEMA), index = False, if_exists='append')\n",
    "    \n",
    "    else: # copy to _randomized schema as is, without randomizing\n",
    "        # Make a new table in _randomized schema\n",
    "        print(\"\\tUploading original version without randomizing\")\n",
    "        statement = \"CREATE TABLE IF NOT EXISTS {0}_randomized.{1} (LIKE {0}.{1} INCLUDING ALL);\".format(INPUT_SCHEMA, table_name)\n",
    "        output = execute_sql(statement, dbname, user, host, password, port, isolation = True, results = False)\n",
    "        \n",
    "        # Copy original data without randomizing\n",
    "        statement = \"SELECT COUNT(*) FROM {}_randomized.{};\".format(INPUT_SCHEMA, table_name)\n",
    "        output = execute_sql(statement, dbname, user, host, password, port)\n",
    "        if output.iloc[0,0]>0: # do nothing if new table already contains data\n",
    "            print(\"\\t*****SKIPPING TABLE {} -- it already has data\".format(table_name))\n",
    "        else:\n",
    "            statement = \"INSERT INTO {0}_randomized.{1} (SELECT * from {0}.{1});\".format(INPUT_SCHEMA, table_name)\n",
    "            output = execute_sql(statement, dbname, user, host, password, port, isolation = True, results = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also randomized the labels, table labels_multiprior_win6mo_lab6mo; forgot to include in input_tables_to_randomize list when previous cell was run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Edit config files so that they point to the newly randomized raw schema\n",
    "\n",
    "Experiment config file being used on the project is prediction_config_multiprior.yaml. Also need to edit all the feature config files under config/features. New versions of config files with an \"_edited\" suffix will be produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_FILES = [\n",
    "    'config/prediction_config_multiprior.yaml', \n",
    "    'config/features/booking_info.yaml',\n",
    "    'config/features/case_flags.yaml',\n",
    "    'config/features/case_info.yaml',\n",
    "    'config/features/case_results.yaml',\n",
    "    'config/features/charge_info.yaml',\n",
    "    'config/features/days_since.yaml',\n",
    "    'config/features/demos.yaml',\n",
    "    'config/features/multi_prior.yaml'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a dictionary of text replacements to apply across every preprocessing & config file. This should include:\n",
    "- Schema and table names that have been changed, i.e. have a \"_randomized\" suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'booking_addl_info': 'booking_addl_info_randomized',\n",
       " 'branch_lkup': 'branch_lkup_randomized',\n",
       " 'case_booking': 'case_booking_randomized',\n",
       " 'case_dispo_lkup': 'case_dispo_lkup_randomized',\n",
       " 'case_flag_lkup': 'case_flag_lkup_randomized',\n",
       " 'case_result_lkup': 'case_result_lkup_randomized',\n",
       " 'charge_lkup': 'charge_lkup_randomized',\n",
       " 'feature_case_info': 'feature_case_info_randomized',\n",
       " 'feature_case_results': 'feature_case_results_randomized',\n",
       " 'feature_casesflag_info': 'feature_casesflag_info_randomized',\n",
       " 'feature_charge_info': 'feature_charge_info_randomized',\n",
       " 'labels_casesonly_multiprior_win6mo_lab6mo': 'labels_casesonly_multiprior_win6mo_lab6mo_randomized',\n",
       " 'labels_multiprior_win6mo_lab6mo': 'labels_multiprior_win6mo_lab6mo_randomized',\n",
       " 'orig_agency_lkup': 'orig_agency_lkup_randomized',\n",
       " 'staging.': 'staging_randomized.'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORD_MAP = {x:x+'_randomized' for x in input_tables_to_randomize}\n",
    "WORD_MAP[INPUT_SCHEMA+'.'] = INPUT_SCHEMA+'_randomized.'\n",
    "WORD_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply find+replace to every config file. Write feature config files to a new folder (config/features_randomized) that will later be referenced when running the experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘features_randomized’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!cd config && mkdir features_randomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating file  config/prediction_config_multiprior_edited.yaml\n",
      "Generating file  config/features_randomized/booking_info_edited.yaml\n",
      "Generating file  config/features_randomized/case_flags_edited.yaml\n",
      "Generating file  config/features_randomized/case_info_edited.yaml\n",
      "Generating file  config/features_randomized/case_results_edited.yaml\n",
      "Generating file  config/features_randomized/charge_info_edited.yaml\n",
      "Generating file  config/features_randomized/days_since_edited.yaml\n",
      "Generating file  config/features_randomized/demos_edited.yaml\n",
      "Generating file  config/features_randomized/multi_prior_edited.yaml\n"
     ]
    }
   ],
   "source": [
    "for filename in CONFIG_FILES:\n",
    "    new_filename = get_new_filename(filename, \"_edited\", {'features': 'features_randomized'})\n",
    "    replace_words_in_file(filename, new_filename, WORD_MAP) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Be sure to open the outputted files (with \"_edited\" suffix) to check that no unexpected replacements were made and that all necessary replacements are made. \n",
    "\n",
    "Model Group Key: We have to manually add a \"purpose\" model group key into the experiment config file. Including a \"purpose\" indicates that this experiment is for leakage detection and helps to distinguish it from existing experiments. Add \"purpose: leakage_detection\" under the user_metadata section, and add \"purpose\" under the model_group_keys section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Run an experiment with this new setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've set up randomized versions of the original schemas in the database and created a new config file for a randomized experiment, it's time to run the actual triage experiment. This is done in an aws ec2 instance.\n",
    "\n",
    "Make sure you have a database.yaml file, required by triage for modeling. See example [here](https://github.com/dssg/la_prosecutor/blob/master/example_database.yaml).\n",
    "\n",
    "Update run.py to reflect the particulars of this new config.\n",
    "- set PROJECT_PATH to the local directory where you want to store output\n",
    "- set n_processes to be less than the number of cores on your machine\n",
    "\n",
    "Run the following command: python run.py -v -c config/prediction_config_multiprior_edited.yaml -f config/features_randomized/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Align the results of randomized experiment against original experiment\n",
    "\n",
    "The model group we're comparing the randomized results to is model_group_id 22; this is the model group created from the original, non-randomized experiment.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that we now see model groups where purpose = \"leakage-detection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.model_groups WHERE model_config LIKE 'leakage_detection'\"\n",
    "model_groups = execute_sql(statement, dbname, user, host, password, port)\n",
    "model_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for the model_group id's you selected\n",
    "GROUP_ID_ORIG = 22\n",
    "GROUP_ID_RAND = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the models relevant to each model group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.models where model_group_id = {};\".format(GROUP_ID_ORIG)\n",
    "models_orig = execute_sql(statement, dbname, user, host, password, port)\n",
    "models_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.models where model_group_id = {};\".format(GROUP_ID_RAND)\n",
    "models_rand = execute_sql(statement, dbname, user, host, password, port)\n",
    "models_rand\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a pair of comparable models on which to test for leakage, i.e. with matching train_end_time. Let's go with the first row of each table, i.e. model_id numbers 1 (original) and 13 (random).  \n",
    "Grab the predictions made by each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variables for the model id's you selected\n",
    "MODEL_ID_ORIG = 1\n",
    "MODEL_ID_RAND = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.predictions where model_id = {};\".format(MODEL_ID_ORIG)\n",
    "predictions_orig = execute_sql(statement, dbname, user, host, password, port)\n",
    "predictions_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_orig_sorted = predictions_orig.sort_values(by=['score', 'label_value'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.predictions where model_id = {};\".format(MODEL_ID_RAND)\n",
    "predictions_rand = execute_sql(statement, dbname, user, host, password, port)\n",
    "predictions_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_rand_sorted = predictions_rand.sort_values(by=['score', 'label_value'], ascending=[False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab the evaluation metrics for each of these models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.evaluations where model_id = {};\".format(MODEL_ID_ORIG)\n",
    "evaluations_orig = execute_sql(statement, dbname, user, host, password, port)\n",
    "evaluations_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statement = \"SELECT * FROM results.evaluations where model_id = {};\".format(MODEL_ID_RAND)\n",
    "evaluations_rand = execute_sql(statement, dbname, user, host, password, port)\n",
    "evaluations_rand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Review the predictions and important features of randomized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
